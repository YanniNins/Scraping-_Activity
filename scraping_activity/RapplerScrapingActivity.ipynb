{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Presidential and Vice Presidential Articles in Rappler.Com\n",
    "\n",
    "## Importing Libraries\n",
    "\n",
    "We import the necessary libraries for web scraping, handling HTTP requests, parsing HTML, and managing data storage and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Scraping Function\n",
    "\n",
    "We define the scrape_article function with a retry mechanism for handling HTTP request failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_article(url):\n",
    "    max_retries = 3\n",
    "    base_delay = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling HTTP Requests with Retries\n",
    "\n",
    "This loop attempts to fetch the webpage, with exponential backoff for retrying if a request fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if response.status_code == 429:\n",
    "                retry_after = response.headers.get(\"Retry-After\")\n",
    "                delay = int(retry_after) if retry_after else base_delay * (2 ** attempt) + random.uniform(0, 1)\n",
    "                print(f\"Attempt {attempt + 1} failed with 429. Retrying after {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "            elif attempt < max_retries - 1:\n",
    "                print(f\"Attempt {attempt + 1} failed. Retrying...\")\n",
    "                time.sleep(base_delay * (2 ** attempt) + random.uniform(0, 1))\n",
    "            else:\n",
    "                print(f\"Maximum retries exceeded. Error: {e}\")\n",
    "                return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the HTML Content\n",
    "\n",
    "We parse the HTML content to extract the article's title, body, keyword presence, and publication year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    title = soup.find('h1', class_='post-single__title').get_text(strip=True) if soup.find('h1', class_='post-single__title') else 'No title found'\n",
    "    body = soup.find('div', class_='post-single__body').get_text(strip=True) if soup.find('div', class_='post-single__body') else ''\n",
    "    has_marcos = 'Marcos' in body\n",
    "    has_sara = 'Sara' in body\n",
    "    pub_year = soup.find('time', class_='entry-date published post__timeago')['datetime'][:4] if soup.find('time', class_='entry-date published post__timeago') and soup.find('time', class_='entry-date published post__timeago').has_attr('datetime') else 'Unknown'\n",
    "    \n",
    "    return {\n",
    "        'url': url,\n",
    "        'title': title,\n",
    "        'body': body,\n",
    "        'has_marcos': has_marcos,\n",
    "        'has_sara': has_sara,\n",
    "        'pub_year': pub_year\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Article URLs\n",
    "\n",
    "We specify the URLs of the articles we want to scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urls = [\n",
    "    'https://www.rappler.com/philippines/marcos-updates-list-priority-measures-ledac-divorce-sogie-bills-excluded-june-2024/',\n",
    "    'https://www.rappler.com/philippines/mindanao/sara-duterte-downplays-opposition-role-thinks-still-friends-with-marcos/',\n",
    "    'https://www.rappler.com/voices/opinion-genuine-ilokano-reflections-marcos-loyalism/',\n",
    "    'https://www.rappler.com/newsbreak/iq/stories-tracking-marcos-disinformation'\n",
    "    # Too many URLs to list here\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Article Data\n",
    "\n",
    "We scrape each URL and store the data in a list of dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "articles = [scrape_article(url) for url in urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Keyword Presence per Year\n",
    "\n",
    "We count the number of articles mentioning \"Marcos\" and \"Sara\" per year and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "keyword_count_per_year = defaultdict(lambda: {'Marcos': 0, 'Sara': 0})\n",
    "\n",
    "for article in articles:\n",
    "    if article:\n",
    "        year = article['pub_year']\n",
    "        if article['has_marcos']:\n",
    "            keyword_count_per_year[year]['Marcos'] += 1\n",
    "        if article['has_sara']:\n",
    "            keyword_count_per_year[year]['Sara'] += 1\n",
    "\n",
    "for year, counts in keyword_count_per_year.items():\n",
    "    print(f\"Year: {year}, Marcos: {counts['Marcos']}, Sara: {counts['Sara']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output:\n",
    "\n",
    "Articles with Marcos only: 72\n",
    "Articles with Sara only: 68\n",
    "Articles with both Marcos and Sara: 19\n",
    "\n",
    "Keyword counts per year:\n",
    "2024: Marcos: 30, Sara: 26, Both: 13\n",
    "2022: Marcos: 17, Sara: 7, Both: 2\n",
    "2021: Marcos: 3, Sara: 5, Both: 2\n",
    "2020: Marcos: 1, Sara: 0, Both: 0\n",
    "2023: Marcos: 13, Sara: 27, Both: 2\n",
    "2017: Marcos: 1, Sara: 0, Both: 0\n",
    "2016: Marcos: 2, Sara: 0, Both: 0\n",
    "2015: Marcos: 3, Sara: 0, Both: 0\n",
    "2019: Marcos: 2, Sara: 3, Both: 0"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
